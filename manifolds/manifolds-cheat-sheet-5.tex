Show that the Lie-Bracket of any pair of smooth vector fields is a smooth vector
field and provide its coordinate representaition.


As we know it suffices to show that \( [X, Y] \) is a derivation, by bilinearity
it's already linear and for \( f, g \in C^\infty(M) \) we have 
\([X, Y](fg) = X (Y (fg)) - Y (X(fg))\)
\(=X(f Yg +gYf)-Y(fXg+gXf)\)
\(=Xf Yg + f XYg + XgYf+gXYf\)
\(-Yf Xg - f YXg -YgXf -gYXf\)
\(= f XYg + gXYf - f YXg - gYXf\)
\(= f [X, Y]g + g[X,Y]f.\)
So the product rule is indeed satisfied.

In the lecture this is theorem 4.4.5,
where all of this is done in local coordinates
(a bit messy).

We can rewrite the last equation in local coordinates 
\( X = X^i \frac{d}{dx^i}, Y = Y^j \frac{d}{dx^j} \) as
\( [X, Y] = (X^i \frac{dY^j}{dx^i} - Y^i \frac{dX^j}{dx^i})\frac{d}{dx^j} \)


Define \( F \)-related vector fields
and the pushforward/pullback of a v.f.

Note that for a smooth map \( F : M \to N \) and v.f. \( X \in \mathcal{X}(M) \), 
\( dF_p(X_p) \in T_{F(p)}(N) \) may not define a vector field again, (e.g. if \( F \)
is not surjective not all points of \( N \) receive a tangent vector).
If \( F \) is not injective the same point may receive different tangent vectors
from different points in its preimage.

Suppose there is some \( Y \in \mathcal{N} \) s.t. \( dF_p(X_p) = Y_{F(p)} \)
we say that \( X,Y \) are \( F \)-related

If \( F \) is a diffeomorphism, this is easy to produce and
for every \( X \in \mathcal{M} \) there is some \( Y \in \mathcal{N} \)
s.t. that the are \( F \)-related, which is called the pushforward of \( X \)
written as \( (F_{\ast}X)_q = dF_{F^{-1}(q)}(X_{F^{-1}(q))} \)
or short \( F_{\ast}X = Y \).
Similarly \( F^{-1} \) does the same
which is referred to as the pullback of a v.f., \( F^\ast X \)

Note that the Lie Bracket behaves very well in regard to \( F \)-related
vector fields, meaning if \( X_i,\ i \in \{1, 2\} \) are \( F \)-related to
\( Y_i,\ i \in \{1, 2\} \) then \( [X_1, X_2], [Y_1, Y_2] \) are \( F \)-related
(which shows that pushforwards/pullbacks distribute over the Lie bracket).


Define a bundle homomorphism and give an example

Let \( \pi : E \to M \), \( \pi' : E' \to M \) be vector bundles,
a continuous map \( F : E \to E' \) is bundle homomorphism if there is
a map \( f : M \to M' \) s.t. \( \pi' \circ F = \pi \circ f \)
and that \( F|_{\pi^{-1}(p)} : E_p \to E'_{f(p)} \) is linear.
One says that \( F \) covers \( f \).

A standard example is a global differential \( dF : TM \to TN \),
which covers \( F \).


Give the definition of the tensor product

(Taken from my algebra notes so a little more general then necessary)
Let \( R \) be a commutative ring and \( M \) and \( N \) be \( R \)-modules. 
The tensor product of \( M \) and \( N \), denoted \( M \otimes_R N \), is an \( R \)-module equipped 
with a bilinear map \( \otimes: M \times N \to M \otimes_R N \) satisfying the following universal property:

For any \( R \)-module \( P \) and any bilinear map \( f: M \times N \to P \) (i.e., a map that is \( R \)-linear in each argument), 
there exists a unique \( R \)-linear map \( \bar{f}: M \otimes_R N \to P \) such that the following diagram commutes:
This means \( f = \bar{f} \circ \otimes \).

To show the existence of the tensor product, we construct it explicitly. 
Consider the free \( R \)-module \( F \) generated by the set \( M \times N \). 
Let \( F \) be the free \( R \)-module with basis elements \( [m, n] \) for \( m \in M \) and \( n \in N \). 
Define a submodule \( K \) of \( F \) generated by the elements of the following forms:
1. \( [m_1 + m_2, \lambda n_1] - \lambda([m_1, n] - [m_2, n]) \) for all \( m_1, m_2 \in M \) and \( n \in N \), \( \lambda \in R \),
2. \( [\lambda m, n_1 + n_2] - \lambda([m, n_1] - [m, n_2]) \) for all \( m \in M \) and \( n_1, n_2 \in N \),

Define \( M \otimes_R N \) as the quotient module \( F / K \). 
Let \( \otimes: M \times N \to M \otimes_R N \) be the map sending \( (m, n) \) to the equivalence class \( [m, n] + K \). 

The universal property then follows by setting the \( \bar{f}([m, n]) = f(m, n) \), that this is well defined, holds because
\( f \) is linear and annihilates \( K \) (its enough to check this for the generators of \( K \)).

Since \( R \)-vector spaces are \( R \)-modules this easily extends to the lecture definition. 

Define the tensor algebra

Naturally the tensor product built on \(M \times N\) can be extended to \(\bigtimes_{i = 1}^{p} M_i\),
which we denote in the case that \(M_i = M_j\) for all \(i, j\) as \(\otimes^{p} M\).
Again for each module \(N\) and \(p\)-linear/multilinear map \(\phi : \bigtimes_{i = 1}^{p} M_i \to N \) 
there is a unique \(\Phi : \otimes^{p} M \to N\) through which \(\phi\) factors \(\phi = \Phi \circ \pi\), 
where \(\pi\) is the canonical projection into the tensor product.
The special cases are 

\(\otimes^{0} M = A\), where \(A\) is the underlying coefficient ring.
\(\otimes^{1} M = M\)

\(x_1 \otimes x_2 \dots \otimes x_p = \pi(x_1, x_2, \dots, x_p) \) and elements of this shape
are called \(p\)-th order or of rank \( p \) tensors. If \(x \in \otimes^{p} M\) can be written as a single elementary
/\(p\)-th order tensor then it is called decomposable. Consider \(\mathbb{R}^{2}\) then \((e_1 \otimes e_2) + (e_2 \otimes e_1)\)
is not decomposable (assume \((e_1 \otimes e_2) + (e_2 \otimes e_1) = (a_1 e_1 + a_2 e_2) \otimes (b_1 e_1 + b_2 e_2)\) after applying
distributivity there will be contradicting assertions for the products of \(a_ib_j\)), but \(e_1 \otimes e_2\) is.

In particular if \(M\) is free with basis \(\{m_i\}_{i \in I}\) then \(\{m_{i_1} \otimes m_{i_2} \dots m_{i_p}\}_{i_j \in I}\)
is a basis for \(\otimes^{p} M\) which is free of rank \(|I|^p\).

One can then define a multiplication for a \(p\)-th order x and \(q\)-th order y in \(\otimes^{p + q} M\) as 
\(x \otimes y = x_1 \otimes \dots x_p \otimes y_1 \otimes \dots y_1\) and more generally on 
\(\bigotimes M = \bigoplus_{p \geq 0} \otimes^{p} M\) as \(x y = \sum_{p \geq 0} \sum_{r + s = p} x_r \otimes y_s\), 
where \(x_r\), \(y_s\) are the \(r\)-th, \(s\)-th order terms in \(x, y\) (which are a sum of these elementary tensors).

This operation is distributive and associative.
Note that only \( \bigotimes M \) is an algebra as otherwise for tensors with summed rank \( a + b > p \)
would not be contained the \( p \)-fold tensor product.


Define the space of \( p \)-multilinear forms, covariant/contravariant
tensors and mixed tensors.

The space of \( p \)-multilinear forms is just the tensor product of \(\bigotimes_{i = 1}^{p} V^\ast\),
where \( V^\ast = \text{Hom}(V, \mathbb{R}) \) is the usual dual space.

Covariant tensors are elements of the \( k \)-fold tensor product \( T^k(V^\ast) = \bigotimes_{i = 1}^{p} V^\ast\)
for example every linear functional \( \omega : V \to \mathbb{R} \) is just a covariant \( 1 \)-tensor so.
A covariant \( 2 \)-tensor is a bilinear form for example the inner product on \( \mathbb{R}^n \) is such an object.
The determinant is a covariant \( n \)-tensor on \( \mathbb{R}^n \).

In the same fashion cotravariant tensors are elements of the \( k \)-fold tensor product \( T^k(V^\ast) = \bigotimes_{i = 1}^{p} V\)
which we understand however as multilinear functionals on forms that is 
\( \alpha \in T^k(V^\ast),\ \alpha : V^\ast \times V^\ast \dots V^\ast \to \mathbb{R}\).

Then a mixed tensor on \( V \) of type \( (k,l) \) is
\( T^{(k,l)}(V) = \underbrace{V \otimes ... \otimes V}_{k \text{ copies}} \otimes \underbrace{V^* \otimes ... \otimes V^*}_{l \text{ copies}}. \)

Some of these spaces are identical:

\( T^{(0,0)}(V) = T^0(V^*) = T^0(V) = \mathbb{R}, \)
\( T^{(0,1)}(V) = T^1(V^*) = V^*, \)
\( T^{(1,0)}(V) = T^1(V) = V, \)
\( T^{(0,k)}(V) = T^k(V^*), \)
\( T^{(k,0)}(V) = T^k(V). \)

Define the canonical tensor bundles on manifolds

Let \(M\) be a smooth manifold, we define the bundle of covariant \(k\)-tensors on \(M\) by
\(T^{k,*}TM = \bigsqcup_{p \in M} T^k (T_p^*M).\)

Analogously, we define the bundle of contravariant \(k\)-tensors by
\(T^{k}TM = \bigsqcup_{p \in M} T^k (T_pM),\)

and the bundle of mixed tensors of type \((k,l)\) by
\(T^{(k,l)}TM = \bigsqcup_{p \in M} T^{(k,l)} (T_pM).\)
Note the special case
\( T^{(0,0)} TM = T^{0}T^\ast M = T^{0}TM = M \times \mathbb{R} \)

Any one of these bundles is called a tensor bundle over \(M\). 
(Thus, the tangent and cotangent bundles are special cases of tensor bundles.) 
A section of a tensor bundle is called a (covariant, contravariant, or mixed) tensor field on \(M\). 
A smooth tensor field is a section that is smooth in the usual sense of smooth sections of vector bundles. Â  
Using the identifications above, we see that contravariant 1-tensor fields are the same as vector fields, and covariant 1-tensor fields are covector fields. 
Because a 0-tensor is just a real number, a 0-tensor field is the same as a continuous real-valued function. 

The spaces of smooth sections of these tensor bundles, \(\Gamma(T^{k}T^{*}M), \Gamma(T^{k}TM)\), 
and \(\Gamma(T^{(k,l)}TM)\) are infinite-dimensional vector spaces over \(\mathbb{R}\), and modules over \(C^{\infty}(M)\). 
In any smooth local coordinates \((x^{i})\), sections of these bundles can be written (using the summation convention) as
\[
A =
\begin{cases}
A_{i_1 \dots i_k} dx^{i_1} \otimes \dots \otimes dx^{i_k}, & A \in \Gamma(T^{k}T^*M); \\
A^{i_1 \dots i_k} \frac{\partial}{\partial x^{i_1}} \otimes \dots \otimes \frac{\partial}{\partial x^{i_k}}, & A \in \Gamma(T^{k}TM); \\
A^{i_1 \dots i_k}_{j_1 \dots j_l} \frac{\partial}{\partial x^{i_1}} \otimes \dots \otimes \frac{\partial}{\partial x^{i_k}} \otimes dx^{j_1} \otimes \dots \otimes dx^{j_l}, & A \in \Gamma(T^{(k,l)} TM).
\end{cases}
\]

The functions \(A_{i_{1}...i_{k}}, A^{i_{1}...i_{k}}\), or \(A_{j_{1}...i_{l}}^{i_{1}...i_{k}}\) 
are called the component functions of \(A\) in the chosen coordinates. 
Because smooth covariant tensor fields occupy most of our attention, 
we adopt the following shorthand notation for the space of all smooth covariant \(k\)-tensor fields:
\(\mathcal{T}^{k}(M)=\Gamma(T^{k}T^{*}M).\)

Define the exterior algebra and prove its existence

A \(p\)-th linear map \(f : \bigtimes^{p} M \to N\) is called alternating if \(f(x_1, \dots, x_n) = 0\), whenever \(x_i = x_j\) for some \(i \neq j\).
In particular if \(2\) is not a zero divisor in the underlying ring \(A\), then \(f\) is alternating iff. 
\(f(x_{\sigma(1)}, \dots, x_{\sigma(p)}) = \text{sgn}(\sigma)f(x_1, \dots, x_p) = 0\) for all \(\sigma \in S_p\).

The exterior algebra \(\bigwedge^{p} M\) satisfies for each alternating \(f : \bigtimes^{p} M \to N\), there is some \(F : \bigwedge^{p} M \to N\)
through which \(f\) factors, \(f = F \circ \pi\).

Its existence can be guaranteed since \(N^p(M) \subset \otimes^{p} M\) with \(N^p(M)\) being generated by \(\{ x_1 \otimes \dots x_p | \exists x_i = x_j, (i \neq j) \}\) 
is indeed a submodule and \(\bigwedge^{p} M = \otimes^{p} M / N^p(M)\) and more generally \(\bigwedge M = \otimes M / N(M)\), since \(N(M)\) is an ideal
in the (infinite) tensor algebra.

If \(M\) is a free module with basis \(\{m_i\}_{i \in I}\), then \(\bigwedge^{p} M = 0\) for \(p > n\). For \(1 \leq p \leq n\) 
\(m_{i_1} \wedge \dots \wedge m_{i_p}\), \(1 \leq i_1 < \dots < i_p \leq n\) is a basis of \(\bigwedge^{p} M\) which is of rank \(\frac{n!}{p!(n - p)!}\)

Define the symmetric algebra and prove its existence

A \(p\)-th linear map \(f : \bigtimes^{p} M \to N\) is called symmetric if \(f(x_1, \dots, x_n) = f(x_{\sigma(1)}, \dots, x_{\sigma(p)})\), for all \(\sigma \in S_p\).

Similarly to the exterior product the symmetric product \(S^p(M) = \text{Sym}^{p}(M)\) 
satisfies for each symmetric \(f : \bigtimes^{p} M \to N\), there is some \(F : \text{Sym}^{p} M \to N\)
through which \(f\) factors, \(f = F \circ \pi\).

Its existence can be guaranteed since \(L^p(M) \subset \otimes^{p} M\) with \(L^p(M)\) generated by \(\{ x_1 \otimes \dots x_p - x_{\sigma(1)}, \dots, x_{\sigma(p)} | \sigma \in S_p \}\), 
is indeed a submodule and \(\text{Sym}^{p}(M) = \otimes^{p} M / L^p(M)\) and more generally \(\text{Sym}(M) = \otimes M / L(M) = \otimes / \bigoplus_{p \geq} L^{p} \), since \(L(M)\) is a (two-sided) ideal.

If \(M\) is a free module with basis \(\{m_i\}_{i \in I}\), then
\(m_{i_1} \cdot \dots \cdot m_{i_p}\), \(1 \leq i_1 < \dots < i_p \leq n\) is a basis of \(\bigwedge^{p} M\), where \(\cdot\) is the notation for the residual class of \(x_1 \otimes x_2 \dots\), and the module is of rank \(\frac{(n + p - 1)!}{(n-1)!(p)!}\) ((n + p - 1) over (n -1))

Further for a free module \(M\) of rank \(n\) there is a natural isomorphism between \(\text{Sym}(M) \simeq A[x_1, \dots, x_n]\),
namely \(\phi(x_1 \cdot x_2 \cdot \dots x_p) = x_1 x_2 \dots x_p\) (note that \(\text{Sym}(M)^{0} = A\)) and multiplication of homogenous
polynomials gives the equivalent multiplication of the residual classes of the tensors.

Explain how alternize/symmetrize multilinear forms

Suppose we have a multilinear form \( \phi : \bigotimes^p V^\ast,\ v \mapsto \phi(v_1, v_2, \dots, v_p) \) 
and denote by \( \phi_\sigma \coloneqq \phi(v_{\sigma(1)}, v_{\sigma(2)}, \dots, v_{\sigma(p)}\), where \( \sigma \in S_p \)
the symmetric group on \( [1, \dots, p] \).

Then the symmetrization of this \( p \)-tensor is defined by \( \text{Sym} : \otimes^p V^\ast \to \bigvee^p V^\ast \),
\( \text{Sym}_p(\phi) = \frac{1}{p!}\sum_{\sigma \in S_p} \phi_\sigma\).

and the alternization of a \( p \)-tensor is defined by \( \text{Alt} : \otimes^p M \to \bigwedge^p M \),
\( \text{Alt}_p(\phi) = \frac{1}{p!}\sum_{\sigma \in S_p} \text{sign} \phi_\sigma\).

Additionally we obtain in the tensor algebra \( \bigvee^{p+q} V^\ast \)
the exterior product of tensors \( \phi, \psi \) of rank \( p \) and \( q \) respectively, via
\( \phi \wedge \psi \coloneqq \frak{(p+q)!}{p!q!}\text{Alt}_{p+q}(\phi \otimes \psi) \)
and on \( \bigwdge^{p+q} V^\ast \)
\( \phi \vee \psi \coloneqq \frak{(p+q)!}{p!q!}\text{Sym}_{p+q}(\phi \otimes \psi) \)

(Yes this is awful to calculate)

The following properties simplify the calculation 
\( \phi \wedge \psi = (-1)^{pq} \psi \wedge \phi \)
\( (\phi \wedge \psi) \wedge \omega = \phi \wedge (\psi \wedge \omega) \)
The symmetric product is both associative and even commutative.



In particular for the exterior product there is the following method:

How can be the calculation of exterior products be simplified?

Let \(V\) be an \(n\)-dimensional vector space, and suppose \((e^1, \dots, e^n)\) is any basis for \(V^*\). 
We now define a collection of \(k\)-covectors on \(V\) that generalize the determinant function on \(\mathbb{R}^n\). 
For each multi-index \(I = (i_1, ..., i_k)\) of length \(k\) such that \(1 \leq i_1, ..., i_k \leq n\), 
define a covariant \(k\)-tensor \(\varepsilon^I = \varepsilon^{i_1 \dots i_k}\) by 

\[\varepsilon^I (v_1, ..., v_k) = \det 
\begin{pmatrix}
\varepsilon^{i_1}(v_1) & \dots & \varepsilon^{i_1}(v_k) \\
\vdots & \ddots & \vdots \\
\varepsilon^{i_k}(v_1) & \dots & \varepsilon^{i_k}(v_k)
\end{pmatrix} = \det 
\begin{pmatrix}
v_1^{i_1} & \dots & v_k^{i_1} \\
\vdots & \ddots & \vdots \\
v_1^{i_k} & \dots & v_k^{i_k}
\end{pmatrix}. 
\]

In other words, if \(v\) denotes the \(n \times k\) matrix whose columns are the components of the vectors \(v_1, ..., v_k\) 
with respect to the basis \((E_i)\) dual to \((e^i)\), then \(\varepsilon^I(v_1, ..., v_k)\) 
is the determinant of the \(k \times k\) submatrix consisting of rows \(i_1, ..., i_k\) of \(v\). 
Because the determinant changes sign whenever two columns are interchanged, 
it is clear that \(\varepsilon^I\) is an alternating \(k\)-tensor. Â  
We call \(\varepsilon^I\) an elementary alternating tensor or elementary \(k\)-covector
and all other \( \omega \in \bigwdge V^\ast \) are just linear combinations of these,
that is 
\( \omega = \sum_{i_1 < i_2 \dots < i_k} \omega_{i_1, i_2, \dots, i_p} \varepsilon^i_1 \wedge \varepsilon^i_2 \dots \varepsilon^i_k \).

Example: In terms of the standard dual basis Â  
\((e^1, e^2, e^3)\) for \((\mathbb{R}^3)^*\), we have
\(e^{13}(v, w) = v^1 w^3 - w^1 v^3 = (e^1 \wedge e^3)(v, w)\);
\(e^{123}(v, w, x) = \det(v, w, x) = (e^1 \wedge e^2 \wedge e^3)(v, w, x)\). 



Define differential forms

Let \( M \) be a differential manifold
For \( 0 \leq r \leq m \) and the  \( \bigwedge^r(T*M) \)
